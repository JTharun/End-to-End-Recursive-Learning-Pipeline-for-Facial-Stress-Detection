{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37dfd910-90fc-43c0-9ee3-22fd12198c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fa49c87-3cbf-4a1a-9729-5e8546998b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4ced012-d349-4415-88a1-17c222158ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/harib/Desktop/Stress/fer2013.csv')\n",
    "#check data shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bff42833-ac2c-401a-a0ab-7806d51c4b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angry</td>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digust</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fear</td>\n",
       "      <td>5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>8989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad</td>\n",
       "      <td>6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>6198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  number\n",
       "0     Angry    4953\n",
       "1    Digust     547\n",
       "2      Fear    5121\n",
       "3     Happy    8989\n",
       "4       Sad    6077\n",
       "5  Surprise    4002\n",
       "6   Neutral    6198"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "emotion_counts = data['emotion'].value_counts(sort=False).reset_index()\n",
    "emotion_counts.columns = ['emotion', 'number']\n",
    "emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3063f7ec-22b3-4d73-9f7b-1eed166e7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28709, 3), \n",
      "validation shape: (3589, 3), \n",
      "test shape: (3589, 3)\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data['Usage']=='Training'].copy()\n",
    "data_val   = data[data['Usage']=='PublicTest'].copy()\n",
    "data_test  = data[data['Usage']=='PrivateTest'].copy()\n",
    "#data_train = data_train[data_train['emotion']!=1]\n",
    "#data_val = data_val[data_val['emotion']!=1]\n",
    "##data_test = data_test[data_test['emotion']!=1]\n",
    "#data_train['emotion'] = data_train['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "#data_test['emotion'] = data_test['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "#data_val['emotion'] = data_val['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "print(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc37a8d3-40cd-438b-a9a5-a6b618e36fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_labels = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def setup_axe(axe,df,title):\n",
    "    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n",
    "    axe.set_xticklabels(emotion_labels)\n",
    "    axe.set_xlabel(\"Emotions\")\n",
    "    axe.set_ylabel(\"Number\")\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # set individual bar lables using above list\n",
    "    for i in axe.patches:\n",
    "        # get_x pulls left or right; get_height pushes up or down\n",
    "        axe.text(i.get_x()-.05, i.get_height()+120, \\\n",
    "                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n",
    "                    rotation=0)\n",
    "\n",
    "   \n",
    "fig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)\n",
    "setup_axe(axes[0],data_train,'train')\n",
    "setup_axe(axes[1],data_val,'validation')\n",
    "setup_axe(axes[2],data_test,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f3176c3-1d2d-41b9-b3c6-8b14f8707d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "width, height = 48, 48\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "num_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0845047d-6342-4911-ae8f-d96a163af99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train _X shape: {},  train _Y shape: (28709, 48, 48, 1)\n",
      "val _X shape: {},  val _Y shape: (3589, 48, 48, 1)\n",
      "test _X shape: {},  test _Y shape: (3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "def CRNO(df, dataName):\n",
    "    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n",
    "    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width, height,1)/255.0   \n",
    "    data_Y = to_categorical(df['emotion'], num_classes)  \n",
    "    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n",
    "    return data_X, data_Y\n",
    "\n",
    "    \n",
    "train_X, train_Y = CRNO(data_train, \"train\") #training data\n",
    "val_X, val_Y     = CRNO(data_val, \"val\") #validation data\n",
    "test_X, test_Y   = CRNO(data_test, \"test\") #test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "150db365-77ba-4a96-998c-f975f5ce0914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-anger\n",
      "\n",
      "Loaded the images of dataset-contempt\n",
      "\n",
      "Loaded the images of dataset-disgust\n",
      "\n",
      "Loaded the images of dataset-fear\n",
      "\n",
      "Loaded the images of dataset-happy\n",
      "\n",
      "Loaded the images of dataset-sadness\n",
      "\n",
      "Loaded the images of dataset-surprise\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(981, 48, 48, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "data_path = 'C:/Users/harib/Desktop/Stress/CK+48'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "numbers = []\n",
    "c=0\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(48,48))\n",
    "        input_img_resize = np.reshape(input_img_resize,(48,48,1))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        c += 1\n",
    "    numbers.append(c)\n",
    "    c = 0\n",
    "        \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c4dcfbc-4dc0-4300-bc83-1bd69a5b73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:134]=0 #135\n",
    "labels[135:188]=6 #54\n",
    "labels[189:365]=1 #177\n",
    "labels[366:440]=2 #75\n",
    "labels[441:647]=3 #207\n",
    "labels[648:731]=4 #84\n",
    "labels[732:980]=5 #249\n",
    "\n",
    "names = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c82aff0e-b94a-4d9d-b510-01d1798eced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5df6d49a-e435-4584-b7b7-54f52d50a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(48, 48, 1))\n",
    "    num_filters = 32\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,3, 2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    #outputs = Dense(10, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, t)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "307c4fd0-6e9f-43b7-a782-e207acf7570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stn in c:\\users\\harib\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\harib\\anaconda3\\lib\\site-packages (from stn) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d968bad-425b-46d5-a70d-e1c4b52f8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FEMSTN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 48, 48, 32)   320         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_81[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 32)   0           ['max_pooling2d_17[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 16, 16, 32)  128         ['activation_15[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 16, 16, 64)   18496       ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_18 (MaxPooling2D  (None, 6, 6, 64)    0           ['conv2d_82[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 6, 64)     0           ['max_pooling2d_18[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 6, 6, 64)    256         ['activation_16[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 6, 6, 96)     55392       ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 6, 6, 96)     0           ['conv2d_83[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 3456)         0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 90)           311130      ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_22 (TFOpLam  (4,)                0           ['activation_17[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_21 (TFOpLam  (4,)                0           ['activation_17[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 90)           0           ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_46 (S  ()                  0           ['tf.compat.v1.shape_22[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_45 (S  ()                  0           ['tf.compat.v1.shape_21[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 32)           2912        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_20 (TFOpLam  (4,)                0           ['activation_17[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.linspace_4 (TFOpLambda)     (6,)                 0           ['tf.__operators__.getitem_46[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.linspace_5 (TFOpLambda)     (6,)                 0           ['tf.__operators__.getitem_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 6)            198         ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_44 (S  ()                  0           ['tf.compat.v1.shape_20[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.meshgrid_2 (TFOpLambda)     [(6, 6),             0           ['tf.linspace_4[0][0]',          \n",
      "                                 (6, 6)]                          'tf.linspace_5[0][0]']          \n",
      "                                                                                                  \n",
      " tf.reshape_20 (TFOpLambda)     (None, 2, 3)         0           ['dense_43[0][0]',               \n",
      "                                                                  'tf.__operators__.getitem_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.reshape_23 (TFOpLambda)     (36,)                0           ['tf.meshgrid_2[0][0]']          \n",
      "                                                                                                  \n",
      " tf.reshape_24 (TFOpLambda)     (36,)                0           ['tf.meshgrid_2[0][1]']          \n",
      "                                                                                                  \n",
      " tf.ones_like_2 (TFOpLambda)    (36,)                0           ['tf.reshape_23[0][0]']          \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_23 (TFOpLam  (3,)                0           ['tf.reshape_20[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.stack_18 (TFOpLambda)       (3, 36)              0           ['tf.reshape_23[0][0]',          \n",
      "                                                                  'tf.reshape_24[0][0]',          \n",
      "                                                                  'tf.ones_like_2[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_47 (S  ()                  0           ['tf.compat.v1.shape_23[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_10 (TFOpLambda)  (1, 3, 36)          0           ['tf.stack_18[0][0]']            \n",
      "                                                                                                  \n",
      " tf.stack_19 (TFOpLambda)       (3,)                 0           ['tf.__operators__.getitem_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.tile_10 (TFOpLambda)        (None, 3, 36)        0           ['tf.expand_dims_10[0][0]',      \n",
      "                                                                  'tf.stack_19[0][0]']            \n",
      "                                                                                                  \n",
      " tf.cast_28 (TFOpLambda)        (None, 2, 3)         0           ['tf.reshape_20[0][0]']          \n",
      "                                                                                                  \n",
      " tf.cast_29 (TFOpLambda)        (None, 3, 36)        0           ['tf.tile_10[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_25 (TFOpLam  (4,)                0           ['activation_17[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_2 (TFOpLambda  (None, 2, 36)       0           ['tf.cast_28[0][0]',             \n",
      " )                                                                'tf.cast_29[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_53 (S  ()                  0           ['tf.compat.v1.shape_25[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.reshape_25 (TFOpLambda)     (None, 2, 6, 6)      0           ['tf.linalg.matmul_2[0][0]',     \n",
      "                                                                  'tf.__operators__.getitem_47[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_45[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_46[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_25 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_53[0][\n",
      " a)                                                              0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_50 (S  (None, 6, 6)        0           ['tf.reshape_25[0][0]']          \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.cast_31 (TFOpLambda)        ()                   0           ['tf.math.subtract_25[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_24 (TFOpLam  (4,)                0           ['activation_17[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.cast_32 (TFOpLambda)        (None, 6, 6)         0           ['tf.__operators__.getitem_50[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_26 (TFOpLambd  ()                  0           ['tf.cast_31[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_52 (S  ()                  0           ['tf.compat.v1.shape_24[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 6, 6)        0           ['tf.cast_32[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_34 (TFOpLambda)        ()                   0           ['tf.math.subtract_26[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_24 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_52[0][\n",
      " a)                                                              0]']                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpLambd  (None, 6, 6)        0           ['tf.__operators__.add_8[0][0]', \n",
      " a)                                                               'tf.cast_34[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_51 (S  (None, 6, 6)        0           ['tf.reshape_25[0][0]']          \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.cast_30 (TFOpLambda)        ()                   0           ['tf.math.subtract_24[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_24[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.cast_33 (TFOpLambda)        (None, 6, 6)         0           ['tf.__operators__.getitem_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_27 (TFOpLambd  ()                  0           ['tf.cast_30[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.floor_4 (TFOpLambda)   (None, 6, 6)         0           ['tf.math.multiply_25[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 6, 6)        0           ['tf.cast_33[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_35 (TFOpLambda)        ()                   0           ['tf.math.subtract_27[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_36 (TFOpLambda)        (None, 6, 6)         0           ['tf.math.floor_4[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpLambd  (None, 6, 6)        0           ['tf.__operators__.add_9[0][0]', \n",
      " a)                                                               'tf.cast_35[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 6, 6)        0           ['tf.cast_36[0][0]']             \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_26[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 48, 48, 32)   320         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf.clip_by_value_9 (TFOpLambda  (None, 6, 6)        0           ['tf.__operators__.add_10[0][0]',\n",
      " )                                                                'tf.cast_31[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.floor_5 (TFOpLambda)   (None, 6, 6)         0           ['tf.math.multiply_27[0][0]']    \n",
      "                                                                                                  \n",
      " tf.clip_by_value_8 (TFOpLambda  (None, 6, 6)        0           ['tf.cast_36[0][0]',             \n",
      " )                                                                'tf.cast_31[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 48, 48, 32)  128         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.cast_37 (TFOpLambda)        (None, 6, 6)         0           ['tf.math.floor_5[0][0]']        \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_26 (TFOpLam  (3,)                0           ['tf.clip_by_value_8[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_27 (TFOpLam  (3,)                0           ['tf.clip_by_value_8[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_28 (TFOpLam  (3,)                0           ['tf.clip_by_value_9[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_29 (TFOpLam  (3,)                0           ['tf.clip_by_value_9[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 48, 48, 32)   0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 6, 6)        0           ['tf.cast_37[0][0]']             \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_54 (S  ()                  0           ['tf.compat.v1.shape_26[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_57 (S  ()                  0           ['tf.compat.v1.shape_27[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_60 (S  ()                  0           ['tf.compat.v1.shape_28[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_63 (S  ()                  0           ['tf.compat.v1.shape_29[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " max_pooling2d_19 (MaxPooling2D  (None, 16, 16, 32)  0           ['activation_18[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.clip_by_value_11 (TFOpLambd  (None, 6, 6)        0           ['tf.__operators__.add_11[0][0]',\n",
      " a)                                                               'tf.cast_30[0][0]']             \n",
      "                                                                                                  \n",
      " tf.range_8 (TFOpLambda)        (None,)              0           ['tf.__operators__.getitem_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.clip_by_value_10 (TFOpLambd  (None, 6, 6)        0           ['tf.cast_37[0][0]',             \n",
      " a)                                                               'tf.cast_30[0][0]']             \n",
      "                                                                                                  \n",
      " tf.range_9 (TFOpLambda)        (None,)              0           ['tf.__operators__.getitem_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.range_10 (TFOpLambda)       (None,)              0           ['tf.__operators__.getitem_60[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.range_11 (TFOpLambda)       (None,)              0           ['tf.__operators__.getitem_63[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 16, 16, 64)   18496       ['max_pooling2d_19[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_39 (TFOpLambda)        (None, 6, 6)         0           ['tf.clip_by_value_9[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_41 (TFOpLambda)        (None, 6, 6)         0           ['tf.clip_by_value_11[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_26 (TFOpLambda)     (None, 1, 1)         0           ['tf.range_8[0][0]',             \n",
      "                                                                  'tf.__operators__.getitem_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_55 (S  ()                  0           ['tf.compat.v1.shape_26[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_56 (S  ()                  0           ['tf.compat.v1.shape_26[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.cast_40 (TFOpLambda)        (None, 6, 6)         0           ['tf.clip_by_value_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_27 (TFOpLambda)     (None, 1, 1)         0           ['tf.range_9[0][0]',             \n",
      "                                                                  'tf.__operators__.getitem_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_58 (S  ()                  0           ['tf.compat.v1.shape_27[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_59 (S  ()                  0           ['tf.compat.v1.shape_27[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.cast_38 (TFOpLambda)        (None, 6, 6)         0           ['tf.clip_by_value_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.reshape_28 (TFOpLambda)     (None, 1, 1)         0           ['tf.range_10[0][0]',            \n",
      "                                                                  'tf.__operators__.getitem_60[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_61 (S  ()                  0           ['tf.compat.v1.shape_28[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_62 (S  ()                  0           ['tf.compat.v1.shape_28[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.reshape_29 (TFOpLambda)     (None, 1, 1)         0           ['tf.range_11[0][0]',            \n",
      "                                                                  'tf.__operators__.getitem_63[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_64 (S  ()                  0           ['tf.compat.v1.shape_29[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_65 (S  ()                  0           ['tf.compat.v1.shape_29[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 16, 16, 64)  256         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.subtract_28 (TFOpLambd  (None, 6, 6)        0           ['tf.cast_39[0][0]',             \n",
      " a)                                                               'tf.math.multiply_25[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_29 (TFOpLambd  (None, 6, 6)        0           ['tf.cast_41[0][0]',             \n",
      " a)                                                               'tf.math.multiply_27[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tile_11 (TFOpLambda)        (None, 6, 6)         0           ['tf.reshape_26[0][0]',          \n",
      "                                                                  'tf.__operators__.getitem_55[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_30 (TFOpLambd  (None, 6, 6)        0           ['tf.cast_39[0][0]',             \n",
      " a)                                                               'tf.math.multiply_25[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_31 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_27[0][0]',    \n",
      " a)                                                               'tf.cast_40[0][0]']             \n",
      "                                                                                                  \n",
      " tf.tile_12 (TFOpLambda)        (None, 6, 6)         0           ['tf.reshape_27[0][0]',          \n",
      "                                                                  'tf.__operators__.getitem_58[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_32 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_25[0][0]',    \n",
      " a)                                                               'tf.cast_38[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract_33 (TFOpLambd  (None, 6, 6)        0           ['tf.cast_41[0][0]',             \n",
      " a)                                                               'tf.math.multiply_27[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tile_13 (TFOpLambda)        (None, 6, 6)         0           ['tf.reshape_28[0][0]',          \n",
      "                                                                  'tf.__operators__.getitem_61[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_62[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_34 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_25[0][0]',    \n",
      " a)                                                               'tf.cast_38[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract_35 (TFOpLambd  (None, 6, 6)        0           ['tf.math.multiply_27[0][0]',    \n",
      " a)                                                               'tf.cast_40[0][0]']             \n",
      "                                                                                                  \n",
      " tf.tile_14 (TFOpLambda)        (None, 6, 6)         0           ['tf.reshape_29[0][0]',          \n",
      "                                                                  'tf.__operators__.getitem_64[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_65[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_28 (TFOpLambd  (None, 6, 6)        0           ['tf.math.subtract_28[0][0]',    \n",
      " a)                                                               'tf.math.subtract_29[0][0]']    \n",
      "                                                                                                  \n",
      " tf.stack_20 (TFOpLambda)       (None, 6, 6, 3)      0           ['tf.tile_11[0][0]',             \n",
      "                                                                  'tf.clip_by_value_10[0][0]',    \n",
      "                                                                  'tf.clip_by_value_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_29 (TFOpLambd  (None, 6, 6)        0           ['tf.math.subtract_30[0][0]',    \n",
      " a)                                                               'tf.math.subtract_31[0][0]']    \n",
      "                                                                                                  \n",
      " tf.stack_21 (TFOpLambda)       (None, 6, 6, 3)      0           ['tf.tile_12[0][0]',             \n",
      "                                                                  'tf.clip_by_value_11[0][0]',    \n",
      "                                                                  'tf.clip_by_value_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_30 (TFOpLambd  (None, 6, 6)        0           ['tf.math.subtract_32[0][0]',    \n",
      " a)                                                               'tf.math.subtract_33[0][0]']    \n",
      "                                                                                                  \n",
      " tf.stack_22 (TFOpLambda)       (None, 6, 6, 3)      0           ['tf.tile_13[0][0]',             \n",
      "                                                                  'tf.clip_by_value_10[0][0]',    \n",
      "                                                                  'tf.clip_by_value_9[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_31 (TFOpLambd  (None, 6, 6)        0           ['tf.math.subtract_34[0][0]',    \n",
      " a)                                                               'tf.math.subtract_35[0][0]']    \n",
      "                                                                                                  \n",
      " tf.stack_23 (TFOpLambda)       (None, 6, 6, 3)      0           ['tf.tile_14[0][0]',             \n",
      "                                                                  'tf.clip_by_value_11[0][0]',    \n",
      "                                                                  'tf.clip_by_value_9[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 6, 6, 64)    0           ['activation_19[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_11 (TFOpLambda)  (None, 6, 6, 1)     0           ['tf.math.multiply_28[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd_8 (TFOp  (None, 6, 6, 96)    0           ['activation_17[0][0]',          \n",
      " Lambda)                                                          'tf.stack_20[0][0]']            \n",
      "                                                                                                  \n",
      " tf.expand_dims_12 (TFOpLambda)  (None, 6, 6, 1)     0           ['tf.math.multiply_29[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd_9 (TFOp  (None, 6, 6, 96)    0           ['activation_17[0][0]',          \n",
      " Lambda)                                                          'tf.stack_21[0][0]']            \n",
      "                                                                                                  \n",
      " tf.expand_dims_13 (TFOpLambda)  (None, 6, 6, 1)     0           ['tf.math.multiply_30[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd_10 (TFO  (None, 6, 6, 96)    0           ['activation_17[0][0]',          \n",
      " pLambda)                                                         'tf.stack_22[0][0]']            \n",
      "                                                                                                  \n",
      " tf.expand_dims_14 (TFOpLambda)  (None, 6, 6, 1)     0           ['tf.math.multiply_31[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd_11 (TFO  (None, 6, 6, 96)    0           ['activation_17[0][0]',          \n",
      " pLambda)                                                         'tf.stack_23[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 6, 6, 96)     55392       ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_32 (TFOpLambd  (None, 6, 6, 96)    0           ['tf.expand_dims_11[0][0]',      \n",
      " a)                                                               'tf.compat.v1.gather_nd_8[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_33 (TFOpLambd  (None, 6, 6, 96)    0           ['tf.expand_dims_12[0][0]',      \n",
      " a)                                                               'tf.compat.v1.gather_nd_9[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_34 (TFOpLambd  (None, 6, 6, 96)    0           ['tf.expand_dims_13[0][0]',      \n",
      " a)                                                               'tf.compat.v1.gather_nd_10[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_35 (TFOpLambd  (None, 6, 6, 96)    0           ['tf.expand_dims_14[0][0]',      \n",
      " a)                                                               'tf.compat.v1.gather_nd_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 6, 6, 96)     0           ['conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.add_n_2 (TFOpLambda)   (None, 6, 6, 96)     0           ['tf.math.multiply_32[0][0]',    \n",
      "                                                                  'tf.math.multiply_33[0][0]',    \n",
      "                                                                  'tf.math.multiply_34[0][0]',    \n",
      "                                                                  'tf.math.multiply_35[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 6, 6, 96)    384         ['activation_20[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 6, 6, 96)     0           ['tf.math.add_n_2[0][0]',        \n",
      "                                                                  'batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 3456)         0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 64)           221248      ['flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 64)           0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 32)           2080        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 32)           0           ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 7)            231         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 7)            231         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 7)            231         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 7)            231         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " average_2 (Average)            (None, 7)            0           ['dense_46[0][0]',               \n",
      "                                                                  'dense_47[0][0]',               \n",
      "                                                                  'dense_48[0][0]',               \n",
      "                                                                  'dense_49[0][0]']               \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 7)            56          ['average_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 688,116\n",
      "Trainable params: 687,540\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from stn import spatial_transformer_network as transformer\n",
    "\n",
    "img_inputs = keras.Input(shape=(48,48,1))\n",
    "\n",
    "locnet = layers.Conv2D(32,3, padding='same')(img_inputs)\n",
    "locnet = layers.MaxPooling2D(3, padding='same')(locnet)\n",
    "locnet = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Conv2D(64,3, padding='same')(locnet)\n",
    "locnet = layers.MaxPooling2D(3, padding='same')(locnet)\n",
    "locnet = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Conv2D(96,3, padding='same')(locnet)\n",
    "feat_map = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Flatten()(feat_map)\n",
    "locnet = layers.Dense(90, activation='relu',kernel_regularizer='l2')(locnet)\n",
    "locnet = layers.Dropout(0.2)(locnet)\n",
    "locnet = layers.Dense(32, activation='relu', kernel_regularizer='l2')(locnet)\n",
    "theta = layers.Dense(6, activation='linear')(locnet)\n",
    "\n",
    "locnet = keras.Model(img_inputs, theta, name=\"locnet\")\n",
    "#locnet.summary()\n",
    "\n",
    "#spatial transformer network\n",
    "outstn = transformer(feat_map,theta)\n",
    "\n",
    "\n",
    "\n",
    "#feature extraction network\n",
    "fe = layers.Conv2D(32,3, padding='same')(img_inputs)\n",
    "fe = layers.BatchNormalization()(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "fe = layers.MaxPooling2D(3,padding='same')(fe)\n",
    "fe = layers.Conv2D(64,3, padding='same')(fe)\n",
    "fe = layers.BatchNormalization()(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "fe = layers.MaxPooling2D(3,padding='same')(fe)\n",
    "fe = layers.Conv2D(96,3, padding='same')(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "do = layers.BatchNormalization()(fe)\n",
    "\n",
    "fe = keras.Model(img_inputs, do, name=\"feature extractor\")\n",
    "#fe.summary()\n",
    "\n",
    "add = layers.Add()([outstn, do])\n",
    "\n",
    "flats = layers.Flatten()(add)\n",
    "flats = layers.Dense(64, activation='relu',  kernel_regularizer='l2')(flats)\n",
    "flats = layers.Dropout(0.4)(flats)\n",
    "flats = layers.Dense(32, activation='relu',  kernel_regularizer='l2')(flats)\n",
    "flats = layers.Dropout(0.4)(flats)\n",
    "#output = layers.Dense(6, activation='softmax')(flats)\n",
    "\n",
    "x1 = layers.Dense(7, activation='linear')(flats)\n",
    "x2 = layers.Dense(7,activation='linear')(flats)\n",
    "x3 = layers.Dense(7,activation='linear')(flats)\n",
    "x4 = layers.Dense(7,activation='linear')(flats)\n",
    "avg = layers.Average()([x1, x2, x3, x4])\n",
    "out = layers.Dense(7, activation='softmax')(avg)\n",
    "\n",
    "model = keras.Model(inputs=img_inputs, outputs=out, name=\"FEMSTN\")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr_schedule), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a5a5268-71a5-4eba-adb4-f43f38bc82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecf5f64e-908e-413a-b570-7247ae9d9636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_87 (Conv2D)          (None, 46, 46, 256)       2560      \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 46, 46, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 46, 46, 256)       0         \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 46, 46, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 46, 46, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 46, 46, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 23, 23, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 23, 23, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 23, 23, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 23, 23, 256)       0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 23, 23, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 23, 23, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 23, 23, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 11, 11, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 11, 11, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 11, 11, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 11, 11, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 11, 11, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 5, 5, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 256)               819456    \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,075,335\n",
      "Trainable params: 3,072,007\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#module 1\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), input_shape=(48, 48, 1), data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "#module 2\n",
    "model.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "#module 3\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#dense 2\n",
    "model.add(Dense(2*2*num_features))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "#dense 4\n",
    "model.add(Dense(2*num_features))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.5,\n",
    "    staircase=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(0.01), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a74d95d-3fb3-43ff-a4d6-1ec230b02374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5f3b1f5-956b-4a97-bc99-70b2878b5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85896ddb-f498-47f5-8130-a937bf4cd7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb87b3-644d-457c-b0fe-7deaf46f4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n",
    "\n",
    "cp_path = './model_bacc.h5'\n",
    "cpl_path = './model_fer_bloss.h5'\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=cp_path,save_best_only=True, save_weights_only=False, verbose=0, monitor='val_accuracy')\n",
    "cpl = tf.keras.callbacks.ModelCheckpoint(filepath=cpl_path,save_best_only=True, save_weights_only=False, verbose=2, monitor='val_loss')\n",
    "history = model.fit(data_generator.flow(train_X, train_Y, 256),\n",
    "                                epochs=1,\n",
    "                                verbose=1, \n",
    "                                callbacks = [cp, cpl, es],\n",
    "                                validation_data=(val_X, val_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5ff168-aeda-446a-b7a3-2c8f459b5c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "me=load_model(\"_mini_XCEPTION.102-0.66(1).hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a7840e-3df5-47a2-9e5e-c04ea9120172",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_1\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=48>, <tf.Tensor: shape=(), dtype=int32, numpy=48>, <tf.Tensor: shape=(), dtype=int32, numpy=1>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-632540f41a81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# model parameters/compilation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m model.compile(optimizer='adam', loss='categorical_crossentropy',\n\u001b[0;32m     31\u001b[0m               metrics=['accuracy'])\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\u001b[0m\u001b[0;32m    201\u001b[0m                      \u001b[1;34mf' but it received {len(inputs)} input tensors. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                      f'Inputs received: {inputs}')\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_1\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=48>, <tf.Tensor: shape=(), dtype=int32, numpy=48>, <tf.Tensor: shape=(), dtype=int32, numpy=1>]"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "input_shape = (48, 48, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'models/'\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = me(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions =pd.read_csv('C:/Users/harib/Desktop/Stress/fer2013.csv')\n",
    "faces = preprocess_input(faces)\n",
    "num_samples, num_classes = emotions.shape\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acacc035-5607-4dd9-b458-995079972f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 62, 62, 8)    72          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 62, 62, 8)   32          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 62, 62, 8)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 60, 60, 8)    576         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 60, 60, 8)   32          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 60, 60, 8)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 60, 60, 16)  200         ['activation_2[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 60, 60, 16)  64          ['separable_conv2d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 60, 60, 16)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 60, 60, 16)  400         ['activation_3[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 60, 60, 16)  64          ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 30, 30, 16)   128         ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 16)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 30, 30, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 30, 30, 16)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 30, 30, 32)  656         ['add_1[0][0]']                  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 30, 30, 32)  128         ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 30, 30, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 30, 30, 32)  1312        ['activation_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 30, 30, 32)  128         ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 15, 15, 32)   512         ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 15, 15, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 15, 15, 32)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 15, 15, 64)  2336        ['add_2[0][0]']                  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 15, 15, 64)  256         ['separable_conv2d_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 15, 15, 64)  4672        ['activation_5[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 15, 15, 64)  256         ['separable_conv2d_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 64)     2048        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 64)     0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (SeparableC  (None, 8, 8, 128)   8768        ['add_3[0][0]']                  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 128)   512         ['separable_conv2d_7[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8, 8, 128)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (SeparableC  (None, 8, 8, 128)   17536       ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 128)   512         ['separable_conv2d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    8192        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 4, 128)    0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 7)      8071        ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 7)           0           ['conv2d_7[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " predictions (Activation)       (None, 7)            0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "me.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "me.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98b3494-7863-45c0-afd0-71d2eabc5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "me.save_weights(\"miniweight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7594c46d-0153-4b45-913f-016b64802355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_explain.core.activations import ExtractActivations\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d710b0ad-a86a-480a-8c6c-2911155e430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x244d3d64640>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_PATH='./test.jpg'\n",
    "img=tf.keras.preprocessing.image.load_img(IMAGE_PATH,target_size=(64,64,1))\n",
    "img=tf.keras.preprocessing.image.img_to_array(img)#view the image\n",
    "plt.imshow(img/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d85b11-8455-4ebd-9973-2b4e4d8340cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 64, 64, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 64, 64, 3)\n    \n    Call arguments received:\n       inputs=tf.Tensor(shape=(None, 64, 64, 3), dtype=float32)\n       training=False\n       mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1c0441f5fe1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimgnet_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimgnet_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimgnet_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;31m#make model predictionsimg=tf.keras.applications.xception.preprocess_input(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\harib\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 64, 64, 3)\n    \n    Call arguments received:\n       inputs=tf.Tensor(shape=(None, 64, 64, 3), dtype=float32)\n       training=False\n       mask=None\n"
     ]
    }
   ],
   "source": [
    "import requests#fetching labels from Imagenet  \n",
    "response=requests.get('https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json')\n",
    "imgnet_map=response.json()\n",
    "imgnet_map={v[1]:k for k, v in imgnet_map.items()}#make model predictionsimg=tf.keras.applications.xception.preprocess_input(img)\n",
    "predictions=me.predict(np.array([img]))\n",
    "decode_predictions(predictions,top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8c456-d7d5-46f9-9516-823efb0e5ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
